# -*- coding: utf-8 -*-
"""simple_cifar10_tf.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sTdoBGfWCpJranXfaDqEc4FeN9Pq9tSx
"""

import tensorflow as tf
import keras
from keras.datasets import cifar10
from keras import layers
from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Activation, Flatten, Dropout, Dense
from keras.models import Model

# Import cifar10 data
train_dat, test_dat = cifar10.load_data()
x_train, y_train = train_dat
x_test, y_test = test_dat

# Normalize pixel data
x_train, x_test = x_train.astype('float32')/255.0, x_test.astype('float32')/255.0
x_train.shape

# One hot encode y data(categorical)
y_train_one_hot = keras.utils.to_categorical(y_train, 10)
y_test_one_hot = keras.utils.to_categorical(y_test, 10)

# Create the model with softmax in last layer for predictions
input_shape = x_train[0].shape
inp = keras.layers.Input(input_shape)
X = Conv2D(filters=3, kernel_size=(2,2), padding="same", activation="relu")(inp)
X = BatchNormalization()(X)
X = Conv2D(filters=5, kernel_size=(2,2), padding="same", activation="relu")(X)
X = MaxPooling2D(pool_size=(2,2))(X)
X = Conv2D(filters=5, kernel_size=(2,2), padding="same", activation="relu")(X)
X = BatchNormalization()(X)
X = MaxPooling2D(pool_size=(2,2))(X)
X = Flatten()(X)
X = Dense(200, activation="relu")(X)
X = Dropout(0.3)(X)
X = Dense(10, activation="softmax")(X)
model = Model(inputs=inp, outputs=X)
model.summary()

# Compile with loss categorical crossentropy for categorical data
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Fit over 100 epochs
model.fit(x_train, y_train_one_hot, validation_data=(x_test, y_test_one_hot), epochs=100)

# Evaluate on validation data
model.evaluate(x_test, y_test_one_hot)

# We can see that the test accuracy is ~60%, a significant drop from the ~80%
# training accuracy. The model has overfit to the training data and merits perhaps
# an architecture shift or some sort of additional regularization.
