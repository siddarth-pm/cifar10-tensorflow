{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "clKLhzl3SCU4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras import layers\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Activation, Flatten, Dropout, Dense\n",
        "from keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import cifar10 data\n",
        "train_dat, test_dat = cifar10.load_data()\n",
        "x_train, y_train = train_dat\n",
        "x_test, y_test = test_dat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCkaWgcmtClM",
        "outputId": "9e9632b6-79e7-49ca-f6f2-0697b2f86205"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 31s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel data\n",
        "x_train, x_test = x_train.astype('float32')/255.0, x_test.astype('float32')/255.0\n",
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GyauzU2tJzo",
        "outputId": "954dc9e3-03fa-47a4-c3cf-3e4471d704f0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One hot encode y data(categorical)\n",
        "y_train_one_hot = keras.utils.to_categorical(y_train, 10)\n",
        "y_test_one_hot = keras.utils.to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "fXgAAvgvtbd7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model with softmax in last layer for predictions\n",
        "input_shape = x_train[0].shape\n",
        "inp = keras.layers.Input(input_shape)\n",
        "X = Conv2D(filters=3, kernel_size=(2,2), padding=\"same\", activation=\"relu\")(inp)\n",
        "X = BatchNormalization()(X)\n",
        "X = Conv2D(filters=5, kernel_size=(2,2), padding=\"same\", activation=\"relu\")(X)\n",
        "X = MaxPooling2D(pool_size=(2,2))(X)\n",
        "X = Conv2D(filters=5, kernel_size=(2,2), padding=\"same\", activation=\"relu\")(X)\n",
        "X = BatchNormalization()(X)\n",
        "X = MaxPooling2D(pool_size=(2,2))(X)\n",
        "X = Flatten()(X)\n",
        "X = Dense(200, activation=\"relu\")(X)\n",
        "X = Dropout(0.3)(X)\n",
        "X = Dense(10, activation=\"softmax\")(X)\n",
        "model = Model(inputs=inp, outputs=X)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGvrLVx2tlA1",
        "outputId": "0a3a0f1a-2136-4dc4-e0f3-870a4e30f2ab"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 32, 32, 3)         39        \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 3)        12        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 5)         65        \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 5)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 5)         105       \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 16, 16, 5)        20        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 5)          0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 320)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 200)               64200     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 200)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                2010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66,451\n",
            "Trainable params: 66,435\n",
            "Non-trainable params: 16\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile with loss categorical crossentropy for categorical data\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "jEk_pFvTuP2L"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit over 100 epochs\n",
        "model.fit(x_train, y_train_one_hot, validation_data=(x_test, y_test_one_hot), epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXBmlGSougNP",
        "outputId": "9f34a099-5211-443c-dabf-5dcf85a1252b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9912 - accuracy: 0.6522 - val_loss: 1.0749 - val_accuracy: 0.6226\n",
            "Epoch 2/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9599 - accuracy: 0.6651 - val_loss: 1.0764 - val_accuracy: 0.6282\n",
            "Epoch 3/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9372 - accuracy: 0.6727 - val_loss: 1.0871 - val_accuracy: 0.6285\n",
            "Epoch 4/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9120 - accuracy: 0.6797 - val_loss: 1.0625 - val_accuracy: 0.6315\n",
            "Epoch 5/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8983 - accuracy: 0.6819 - val_loss: 1.0696 - val_accuracy: 0.6331\n",
            "Epoch 6/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.8828 - accuracy: 0.6904 - val_loss: 1.0869 - val_accuracy: 0.6313\n",
            "Epoch 7/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.8601 - accuracy: 0.6988 - val_loss: 1.1712 - val_accuracy: 0.6155\n",
            "Epoch 8/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8553 - accuracy: 0.6976 - val_loss: 1.0965 - val_accuracy: 0.6259\n",
            "Epoch 9/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8344 - accuracy: 0.7078 - val_loss: 1.1010 - val_accuracy: 0.6329\n",
            "Epoch 10/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8269 - accuracy: 0.7087 - val_loss: 1.1235 - val_accuracy: 0.6247\n",
            "Epoch 11/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.8154 - accuracy: 0.7106 - val_loss: 1.1189 - val_accuracy: 0.6333\n",
            "Epoch 12/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.8072 - accuracy: 0.7129 - val_loss: 1.1292 - val_accuracy: 0.6319\n",
            "Epoch 13/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7988 - accuracy: 0.7135 - val_loss: 1.1335 - val_accuracy: 0.6279\n",
            "Epoch 14/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.7844 - accuracy: 0.7216 - val_loss: 1.1573 - val_accuracy: 0.6257\n",
            "Epoch 15/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.7740 - accuracy: 0.7246 - val_loss: 1.1637 - val_accuracy: 0.6299\n",
            "Epoch 16/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7689 - accuracy: 0.7263 - val_loss: 1.1626 - val_accuracy: 0.6254\n",
            "Epoch 17/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.7598 - accuracy: 0.7298 - val_loss: 1.1724 - val_accuracy: 0.6214\n",
            "Epoch 18/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7493 - accuracy: 0.7348 - val_loss: 1.1931 - val_accuracy: 0.6172\n",
            "Epoch 19/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7438 - accuracy: 0.7343 - val_loss: 1.1669 - val_accuracy: 0.6236\n",
            "Epoch 20/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7334 - accuracy: 0.7373 - val_loss: 1.1782 - val_accuracy: 0.6191\n",
            "Epoch 21/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.7312 - accuracy: 0.7391 - val_loss: 1.1958 - val_accuracy: 0.6208\n",
            "Epoch 22/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7217 - accuracy: 0.7430 - val_loss: 1.1807 - val_accuracy: 0.6199\n",
            "Epoch 23/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7099 - accuracy: 0.7457 - val_loss: 1.2065 - val_accuracy: 0.6219\n",
            "Epoch 24/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.7054 - accuracy: 0.7479 - val_loss: 1.2102 - val_accuracy: 0.6207\n",
            "Epoch 25/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.7085 - accuracy: 0.7469 - val_loss: 1.2235 - val_accuracy: 0.6186\n",
            "Epoch 26/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6954 - accuracy: 0.7526 - val_loss: 1.2162 - val_accuracy: 0.6213\n",
            "Epoch 27/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6894 - accuracy: 0.7519 - val_loss: 1.2518 - val_accuracy: 0.6263\n",
            "Epoch 28/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6857 - accuracy: 0.7541 - val_loss: 1.2941 - val_accuracy: 0.6147\n",
            "Epoch 29/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6825 - accuracy: 0.7551 - val_loss: 1.2588 - val_accuracy: 0.6196\n",
            "Epoch 30/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6766 - accuracy: 0.7571 - val_loss: 1.2634 - val_accuracy: 0.6196\n",
            "Epoch 31/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6744 - accuracy: 0.7587 - val_loss: 1.2640 - val_accuracy: 0.6181\n",
            "Epoch 32/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6675 - accuracy: 0.7598 - val_loss: 1.3152 - val_accuracy: 0.6152\n",
            "Epoch 33/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6632 - accuracy: 0.7619 - val_loss: 1.2943 - val_accuracy: 0.6196\n",
            "Epoch 34/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6624 - accuracy: 0.7626 - val_loss: 1.2860 - val_accuracy: 0.6189\n",
            "Epoch 35/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6495 - accuracy: 0.7668 - val_loss: 1.2832 - val_accuracy: 0.6234\n",
            "Epoch 36/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6480 - accuracy: 0.7684 - val_loss: 1.2974 - val_accuracy: 0.6158\n",
            "Epoch 37/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6440 - accuracy: 0.7700 - val_loss: 1.3192 - val_accuracy: 0.6171\n",
            "Epoch 38/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6493 - accuracy: 0.7667 - val_loss: 1.3215 - val_accuracy: 0.6163\n",
            "Epoch 39/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6384 - accuracy: 0.7704 - val_loss: 1.3086 - val_accuracy: 0.6173\n",
            "Epoch 40/100\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6330 - accuracy: 0.7713 - val_loss: 1.3338 - val_accuracy: 0.6179\n",
            "Epoch 41/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6296 - accuracy: 0.7734 - val_loss: 1.3136 - val_accuracy: 0.6145\n",
            "Epoch 42/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6285 - accuracy: 0.7734 - val_loss: 1.3286 - val_accuracy: 0.6194\n",
            "Epoch 43/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6289 - accuracy: 0.7721 - val_loss: 1.3250 - val_accuracy: 0.6150\n",
            "Epoch 44/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6210 - accuracy: 0.7736 - val_loss: 1.3311 - val_accuracy: 0.6167\n",
            "Epoch 45/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6151 - accuracy: 0.7786 - val_loss: 1.3315 - val_accuracy: 0.6163\n",
            "Epoch 46/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6102 - accuracy: 0.7793 - val_loss: 1.3405 - val_accuracy: 0.6116\n",
            "Epoch 47/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6122 - accuracy: 0.7779 - val_loss: 1.3564 - val_accuracy: 0.6143\n",
            "Epoch 48/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.6116 - accuracy: 0.7776 - val_loss: 1.3882 - val_accuracy: 0.6157\n",
            "Epoch 49/100\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 0.6044 - accuracy: 0.7812 - val_loss: 1.3620 - val_accuracy: 0.6127\n",
            "Epoch 50/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6061 - accuracy: 0.7795 - val_loss: 1.3847 - val_accuracy: 0.6165\n",
            "Epoch 51/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5984 - accuracy: 0.7844 - val_loss: 1.3947 - val_accuracy: 0.6131\n",
            "Epoch 52/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5945 - accuracy: 0.7855 - val_loss: 1.3681 - val_accuracy: 0.6083\n",
            "Epoch 53/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5985 - accuracy: 0.7817 - val_loss: 1.3684 - val_accuracy: 0.6138\n",
            "Epoch 54/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5952 - accuracy: 0.7828 - val_loss: 1.3822 - val_accuracy: 0.6054\n",
            "Epoch 55/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5927 - accuracy: 0.7852 - val_loss: 1.3589 - val_accuracy: 0.6070\n",
            "Epoch 56/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5831 - accuracy: 0.7896 - val_loss: 1.4011 - val_accuracy: 0.6127\n",
            "Epoch 57/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5884 - accuracy: 0.7870 - val_loss: 1.3924 - val_accuracy: 0.6069\n",
            "Epoch 58/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5837 - accuracy: 0.7897 - val_loss: 1.4306 - val_accuracy: 0.6102\n",
            "Epoch 59/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5810 - accuracy: 0.7888 - val_loss: 1.3857 - val_accuracy: 0.6089\n",
            "Epoch 60/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5795 - accuracy: 0.7878 - val_loss: 1.3924 - val_accuracy: 0.6065\n",
            "Epoch 61/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5807 - accuracy: 0.7911 - val_loss: 1.3796 - val_accuracy: 0.6122\n",
            "Epoch 62/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5745 - accuracy: 0.7923 - val_loss: 1.4190 - val_accuracy: 0.6047\n",
            "Epoch 63/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5774 - accuracy: 0.7904 - val_loss: 1.4449 - val_accuracy: 0.6080\n",
            "Epoch 64/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5706 - accuracy: 0.7918 - val_loss: 1.4385 - val_accuracy: 0.6061\n",
            "Epoch 65/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5669 - accuracy: 0.7936 - val_loss: 1.4468 - val_accuracy: 0.6032\n",
            "Epoch 66/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5660 - accuracy: 0.7929 - val_loss: 1.4797 - val_accuracy: 0.6067\n",
            "Epoch 67/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5676 - accuracy: 0.7961 - val_loss: 1.5070 - val_accuracy: 0.6078\n",
            "Epoch 68/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5624 - accuracy: 0.7934 - val_loss: 1.4469 - val_accuracy: 0.6004\n",
            "Epoch 69/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5670 - accuracy: 0.7953 - val_loss: 1.4602 - val_accuracy: 0.6062\n",
            "Epoch 70/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5561 - accuracy: 0.7967 - val_loss: 1.4821 - val_accuracy: 0.6028\n",
            "Epoch 71/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5599 - accuracy: 0.7964 - val_loss: 1.4786 - val_accuracy: 0.5990\n",
            "Epoch 72/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5561 - accuracy: 0.7977 - val_loss: 1.4933 - val_accuracy: 0.6031\n",
            "Epoch 73/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5540 - accuracy: 0.7994 - val_loss: 1.4572 - val_accuracy: 0.6020\n",
            "Epoch 74/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5453 - accuracy: 0.8013 - val_loss: 1.4899 - val_accuracy: 0.6028\n",
            "Epoch 75/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5485 - accuracy: 0.7986 - val_loss: 1.4960 - val_accuracy: 0.6029\n",
            "Epoch 76/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5482 - accuracy: 0.7998 - val_loss: 1.5183 - val_accuracy: 0.6026\n",
            "Epoch 77/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5481 - accuracy: 0.8008 - val_loss: 1.4993 - val_accuracy: 0.6030\n",
            "Epoch 78/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5397 - accuracy: 0.8035 - val_loss: 1.5003 - val_accuracy: 0.5997\n",
            "Epoch 79/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5401 - accuracy: 0.8041 - val_loss: 1.5517 - val_accuracy: 0.6064\n",
            "Epoch 80/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5444 - accuracy: 0.8018 - val_loss: 1.5601 - val_accuracy: 0.5989\n",
            "Epoch 81/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5368 - accuracy: 0.8023 - val_loss: 1.5244 - val_accuracy: 0.5982\n",
            "Epoch 82/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5374 - accuracy: 0.8061 - val_loss: 1.5551 - val_accuracy: 0.6069\n",
            "Epoch 83/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5360 - accuracy: 0.8052 - val_loss: 1.5404 - val_accuracy: 0.6031\n",
            "Epoch 84/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5346 - accuracy: 0.8057 - val_loss: 1.5441 - val_accuracy: 0.5971\n",
            "Epoch 85/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5345 - accuracy: 0.8046 - val_loss: 1.5697 - val_accuracy: 0.5998\n",
            "Epoch 86/100\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.5353 - accuracy: 0.8028 - val_loss: 1.5648 - val_accuracy: 0.5995\n",
            "Epoch 87/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5298 - accuracy: 0.8073 - val_loss: 1.5425 - val_accuracy: 0.6022\n",
            "Epoch 88/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5302 - accuracy: 0.8058 - val_loss: 1.6564 - val_accuracy: 0.5993\n",
            "Epoch 89/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5304 - accuracy: 0.8052 - val_loss: 1.6121 - val_accuracy: 0.5988\n",
            "Epoch 90/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5299 - accuracy: 0.8086 - val_loss: 1.5311 - val_accuracy: 0.5966\n",
            "Epoch 91/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5220 - accuracy: 0.8101 - val_loss: 1.5757 - val_accuracy: 0.5981\n",
            "Epoch 92/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5260 - accuracy: 0.8073 - val_loss: 1.6361 - val_accuracy: 0.6024\n",
            "Epoch 93/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5201 - accuracy: 0.8098 - val_loss: 1.6394 - val_accuracy: 0.5975\n",
            "Epoch 94/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5215 - accuracy: 0.8114 - val_loss: 1.5624 - val_accuracy: 0.5988\n",
            "Epoch 95/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5163 - accuracy: 0.8102 - val_loss: 1.5786 - val_accuracy: 0.5973\n",
            "Epoch 96/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5177 - accuracy: 0.8121 - val_loss: 1.6479 - val_accuracy: 0.5984\n",
            "Epoch 97/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5156 - accuracy: 0.8114 - val_loss: 1.6029 - val_accuracy: 0.5947\n",
            "Epoch 98/100\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5150 - accuracy: 0.8122 - val_loss: 1.5777 - val_accuracy: 0.5999\n",
            "Epoch 99/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5173 - accuracy: 0.8111 - val_loss: 1.5829 - val_accuracy: 0.5975\n",
            "Epoch 100/100\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5125 - accuracy: 0.8122 - val_loss: 1.6803 - val_accuracy: 0.5980\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f88b05981c0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on validation data\n",
        "model.evaluate(x_test, y_test_one_hot)"
      ],
      "metadata": {
        "id": "fSpHMgeyumJL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aae7ba38-2ae3-4eae-c87c-61f3f046dcca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 1.6803 - accuracy: 0.5980\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.6802783012390137, 0.5979999899864197]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can see that the test accuracy is ~60%, a significant drop from the ~80%\n",
        "# training accuracy. The model has overfit to the training data and merits perhaps\n",
        "# an architecture shift or some sort of additional regularization."
      ],
      "metadata": {
        "id": "qhud4AIJyaOM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}